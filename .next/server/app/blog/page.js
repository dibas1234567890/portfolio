(()=>{var e={};e.id=831,e.ids=[831],e.modules={403:(e,t,n)=>{"use strict";n.d(t,{DX:()=>r});var a=n(1120);function i(e,t){if("function"==typeof e)return e(t);null!=e&&(e.current=t)}var s=n(7413),r=a.forwardRef((e,t)=>{let{children:n,...i}=e,r=a.Children.toArray(n),l=r.find(c);if(l){let e=l.props.children,n=r.map(t=>t!==l?t:a.Children.count(e)>1?a.Children.only(null):a.isValidElement(e)?e.props.children:null);return(0,s.jsx)(o,{...i,ref:t,children:a.isValidElement(e)?a.cloneElement(e,void 0,n):null})}return(0,s.jsx)(o,{...i,ref:t,children:n})});r.displayName="Slot";var o=a.forwardRef((e,t)=>{let{children:n,...s}=e;if(a.isValidElement(n)){let e=function(e){let t=Object.getOwnPropertyDescriptor(e.props,"ref")?.get,n=t&&"isReactWarning"in t&&t.isReactWarning;return n?e.ref:(n=(t=Object.getOwnPropertyDescriptor(e,"ref")?.get)&&"isReactWarning"in t&&t.isReactWarning)?e.props.ref:e.props.ref||e.ref}(n);return a.cloneElement(n,{...function(e,t){let n={...t};for(let a in t){let i=e[a],s=t[a];/^on[A-Z]/.test(a)?i&&s?n[a]=(...e)=>{s(...e),i(...e)}:i&&(n[a]=i):"style"===a?n[a]={...i,...s}:"className"===a&&(n[a]=[i,s].filter(Boolean).join(" "))}return{...e,...n}}(s,n.props),ref:t?function(...e){return t=>{let n=!1,a=e.map(e=>{let a=i(e,t);return n||"function"!=typeof a||(n=!0),a});if(n)return()=>{for(let t=0;t<a.length;t++){let n=a[t];"function"==typeof n?n():i(e[t],null)}}}}(t,e):e})}return a.Children.count(n)>1?a.Children.only(null):null});o.displayName="SlotClone";var l=({children:e})=>(0,s.jsx)(s.Fragment,{children:e});function c(e){return a.isValidElement(e)&&e.type===l}},846:e=>{"use strict";e.exports=require("next/dist/compiled/next-server/app-page.runtime.prod.js")},918:(e,t,n)=>{"use strict";n.d(t,{A:()=>a});let a=(0,n(6373).A)("Calendar",[["path",{d:"M8 2v4",key:"1cmpym"}],["path",{d:"M16 2v4",key:"4m81vk"}],["rect",{width:"18",height:"18",x:"3",y:"4",rx:"2",key:"1hopcy"}],["path",{d:"M3 10h18",key:"8toen8"}]])},1358:(e,t,n)=>{"use strict";n.d(t,{Wu:()=>c,ZB:()=>l,Zp:()=>r,aR:()=>o});var a=n(7413),i=n(1120),s=n(6819);let r=i.forwardRef(({className:e,...t},n)=>(0,a.jsx)("div",{ref:n,className:(0,s.cn)("rounded-lg border bg-card text-card-foreground shadow-sm",e),...t}));r.displayName="Card";let o=i.forwardRef(({className:e,...t},n)=>(0,a.jsx)("div",{ref:n,className:(0,s.cn)("flex flex-col space-y-1.5 p-6",e),...t}));o.displayName="CardHeader";let l=i.forwardRef(({className:e,...t},n)=>(0,a.jsx)("div",{ref:n,className:(0,s.cn)("text-2xl font-semibold leading-none tracking-tight",e),...t}));l.displayName="CardTitle",i.forwardRef(({className:e,...t},n)=>(0,a.jsx)("div",{ref:n,className:(0,s.cn)("text-sm text-muted-foreground",e),...t})).displayName="CardDescription";let c=i.forwardRef(({className:e,...t},n)=>(0,a.jsx)("div",{ref:n,className:(0,s.cn)("p-6 pt-0",e),...t}));c.displayName="CardContent",i.forwardRef(({className:e,...t},n)=>(0,a.jsx)("div",{ref:n,className:(0,s.cn)("flex items-center p-6 pt-0",e),...t})).displayName="CardFooter"},1382:(e,t,n)=>{"use strict";n.d(t,{A:()=>a});let a=(0,n(6373).A)("Users",[["path",{d:"M16 21v-2a4 4 0 0 0-4-4H6a4 4 0 0 0-4 4v2",key:"1yyitq"}],["circle",{cx:"9",cy:"7",r:"4",key:"nufk8"}],["path",{d:"M22 21v-2a4 4 0 0 0-3-3.87",key:"kshegd"}],["path",{d:"M16 3.13a4 4 0 0 1 0 7.75",key:"1da9ce"}]])},1979:(e,t,n)=>{"use strict";n.d(t,{default:()=>a});let a=(0,n(2907).registerClientReference)(function(){throw Error("Attempted to call the default export of \"D:\\\\dibas-portfolio\\\\components\\\\navigation.tsx\" from the server, but it's on the client. It's not possible to invoke a client function from the server, it can only be rendered as a Component or passed to props of a Client Component.")},"D:\\dibas-portfolio\\components\\navigation.tsx","default")},2399:(e,t,n)=>{"use strict";n.r(t),n.d(t,{default:()=>f});var a=n(7413),i=n(1358),s=n(9455),r=n(4592),o=n(1382),l=n(6700),c=n(5805),d=n(2654),m=n(918),h=n(3148);let u=(0,n(6373).A)("ArrowRight",[["path",{d:"M5 12h14",key:"1ays0h"}],["path",{d:"m12 5 7 7-7 7",key:"xquz4c"}]]);var p=n(4536),g=n.n(p);function f(){let e=[{id:"ai-democratization",title:"The Democratization of AI: Breaking Down Barriers to Innovation",excerpt:"Exploring how AI tools and platforms are becoming accessible to everyone, not just tech giants, and what this means for the future of innovation.",content:`The artificial intelligence revolution is no longer confined to the ivory towers of tech giants and research institutions. We're witnessing an unprecedented democratization of AI that's reshaping how we think about innovation, creativity, and problem-solving.

## The Great Equalizer

Just a few years ago, building AI applications required massive computational resources, specialized hardware, and teams of PhD-level researchers. Today, a developer in Nepal can access the same powerful language models that power ChatGPT, build sophisticated AI agents, and deploy them globally—all from a laptop.

This shift is profound. When I work on projects like the Roman Nepali to Devanagari transliterator, I'm leveraging the same foundational technologies that billion-dollar companies use, but applying them to solve local problems that matter to my community.

## The New AI Stack

The democratization comes through several key layers:

**1. Model APIs**: OpenAI, Anthropic, and others provide API access to state-of-the-art models
**2. Open Source Models**: Llama, Mistral, and others offer free alternatives
**3. Development Frameworks**: LangChain, AI SDK, and similar tools abstract complexity
**4. Cloud Infrastructure**: Vercel, AWS, and others provide scalable deployment
**5. Educational Resources**: YouTube, documentation, and communities share knowledge freely

## Local Impact, Global Technology

In my work at Palmmind, we've built AI solutions for local governments in Nepal, creating services for low-resource languages that were previously ignored by major tech companies. This is the power of democratized AI—it enables solutions for niche problems that wouldn't be profitable for large corporations.

## The Challenges Ahead

However, democratization isn't without risks:
- **Quality Control**: Not all AI applications are built with proper safeguards
- **Ethical Considerations**: Easier access means more potential for misuse
- **Digital Divide**: Access still requires internet, devices, and technical literacy
- **Economic Disruption**: Rapid AI adoption can displace traditional jobs

## Building Responsibly

As AI becomes more accessible, we have a responsibility to:
- Implement proper security measures (like we did achieving <2% vulnerability with Garak)
- Consider the societal impact of our applications
- Share knowledge and mentor others entering the field
- Build solutions that genuinely improve people's lives

The democratization of AI is unstoppable, and that's largely a good thing. But with great power comes great responsibility. As builders in this space, we must ensure that this democratization leads to innovation that benefits everyone, not just those with the resources to exploit it.`,date:"2024-12-15",readTime:"8 min read",tags:["AI Democratization","Innovation","Technology Access","Local Solutions"],icon:o.A,color:"text-cyan-400"},{id:"ai-governance",title:"AI in Governance: The Future of Digital Democracy",excerpt:"Can artificial intelligence replace traditional governance structures? Exploring the potential and perils of AI-driven decision making in public administration.",content:`As AI systems become more sophisticated, a provocative question emerges: Could artificial intelligence eventually replace human governance? While this might sound like science fiction, the reality is that AI is already transforming how governments operate and make decisions.

## The Current State

Governments worldwide are already using AI for:
- **Predictive Policing**: Algorithms that predict crime hotspots
- **Social Services**: AI systems that determine benefit eligibility
- **Traffic Management**: Smart city systems that optimize traffic flow
- **Document Processing**: Automated processing of permits and applications
- **Fraud Detection**: AI systems that identify suspicious activities

In my work building LLM-based services for local governments, I've seen firsthand how AI can streamline bureaucratic processes and make government services more accessible to citizens.

## The Promise of AI Governance

**Efficiency**: AI systems can process information and make decisions 24/7 without fatigue
**Consistency**: Algorithms apply rules uniformly without human bias or favoritism
**Data-Driven**: Decisions based on comprehensive data analysis rather than intuition
**Accessibility**: AI interfaces can make government services available in multiple languages
**Cost-Effective**: Reduced need for large bureaucratic structures

## The Perils We Must Consider

**Algorithmic Bias**: AI systems can perpetuate or amplify existing societal biases
**Lack of Empathy**: Human situations often require understanding context and emotion
**Transparency**: "Black box" AI decisions can be difficult to explain or challenge
**Accountability**: Who is responsible when an AI system makes a wrong decision?
**Democratic Legitimacy**: Can unelected algorithms have the authority to govern?

## A Hybrid Future

Rather than complete replacement, I envision a hybrid model where AI augments human governance:

**AI as Advisor**: Systems that analyze data and provide recommendations to human decision-makers
**Automated Routine Tasks**: AI handles standard processes while humans focus on complex cases
**Enhanced Citizen Services**: Chatbots and AI assistants that provide 24/7 government support
**Predictive Governance**: AI that helps anticipate and prevent problems before they occur

## Real-World Implementation

In my experience building AI systems for government use, the key is starting small:
1. **Document Processing**: Automating routine paperwork and applications
2. **Citizen Support**: AI chatbots that can answer common questions
3. **Data Analysis**: AI that helps officials understand trends and patterns
4. **Language Services**: AI translation for multilingual populations

## The Path Forward

The question isn't whether AI will replace governance, but how we can integrate AI responsibly into democratic systems. This requires:

- **Transparent Algorithms**: Citizens must understand how AI systems make decisions
- **Human Oversight**: Critical decisions should always have human review
- **Regular Audits**: AI systems must be continuously monitored for bias and errors
- **Public Participation**: Citizens should have input on how AI is used in governance
- **Ethical Frameworks**: Clear guidelines for AI use in public administration

## Conclusion

AI won't replace human governance, but it will fundamentally transform it. The goal should be to harness AI's efficiency and analytical power while preserving the human judgment, empathy, and democratic accountability that are essential to good governance.

As we build these systems, we must remember that technology serves people, not the other way around. The future of governance lies not in choosing between human and artificial intelligence, but in combining them thoughtfully to create more effective, accessible, and fair government services.`,date:"2024-12-10",readTime:"12 min read",tags:["AI Governance","Digital Democracy","Public Administration","Ethics"],icon:l.A,color:"text-pink-400"},{id:"llm-optimization",title:"Optimizing LLMs for Production: Lessons from the Trenches",excerpt:"Real-world strategies for deploying large language models in production environments, from prompt optimization to KV caching.",content:`Deploying large language models in production is vastly different from experimenting in a Jupyter notebook. After building multiple LLM-powered systems at Palmmind, here are the hard-won lessons about optimization that actually matter.

## The Performance Trinity

When optimizing LLMs for production, you're balancing three critical factors:
1. **Latency**: How fast can you get a response?
2. **Quality**: How good is the output?
3. **Cost**: How much does each request cost?

Improving one often means compromising on others, so understanding your use case is crucial.

## Prompt Engineering: The 80/20 Rule

**The Problem**: Most developers spend 80% of their time on model selection and 20% on prompts. It should be the reverse.

**What Actually Works**:
- **Few-shot examples**: Include 2-3 perfect examples in your prompt
- **Chain of thought**: Ask the model to "think step by step"
- **Role definition**: Clearly define what the AI should act as
- **Output formatting**: Specify exact format requirements
- **Constraint setting**: Tell the model what NOT to do

In our Roman Nepali transliterator, we achieved 0.01-1 second latency primarily through prompt optimization, not model changes.

## KV Caching: The Secret Weapon

**Key-Value caching** is often overlooked but can dramatically improve performance:

- **System prompts**: Cache the system prompt across conversations
- **Context reuse**: Reuse conversation context when possible
- **Batch processing**: Process similar requests together
- **Prefix caching**: Cache common prompt prefixes

We saw 40% latency improvements just by optimizing our KV cache usage.

## Model Selection Strategy

**Don't default to the biggest model**:
- GPT-4o for complex reasoning
- GPT-4o-mini for most tasks
- Claude for long context
- Local models for sensitive data

**Quantization works**: We regularly use quantized models with minimal quality loss but significant speed gains.

## RAG Optimization

**Retrieval-Augmented Generation** has its own optimization challenges:

**Chunking Strategy**:
- Semantic chunking > fixed-size chunking
- Overlap chunks by 10-20%
- Include metadata in chunks

**Vector Search**:
- Use hybrid search (semantic + keyword)
- Experiment with different embedding models
- Implement reranking for better results

**Context Management**:
- Limit context to relevant chunks only
- Use summarization for long documents
- Implement context compression

## Monitoring and Observability

**What to Track**:
- Response latency (p50, p95, p99)
- Token usage and costs
- Error rates and types
- User satisfaction scores
- Model drift over time

**Tools We Use**:
- Custom logging for prompt/response pairs
- Token counting for cost tracking
- A/B testing for prompt variations
- User feedback collection

## Cost Optimization

**Strategies That Work**:
- Use smaller models for simpler tasks
- Implement request caching
- Batch similar requests
- Use streaming for better UX perception
- Monitor and alert on cost spikes

## Security Considerations

**Prompt Injection Defense**:
- Input sanitization
- Output filtering
- Rate limiting
- User authentication
- Audit logging

We achieved <2% vulnerability using the Garak framework by implementing these systematically.

## The Human Factor

**Don't forget the humans**:
- Provide fallback to human support
- Implement confidence scoring
- Allow user feedback and corrections
- Regular human review of outputs

## Conclusion

LLM optimization is more art than science. Start with good prompts, measure everything, and optimize based on real user needs, not theoretical benchmarks. The best optimization is often the simplest one that actually solves your users' problems.`,date:"2024-12-05",readTime:"10 min read",tags:["LLM Optimization","Production","Performance","RAG"],icon:c.A,color:"text-purple-400"},{id:"future-ai-agents",title:"The Rise of Autonomous AI Agents: Beyond Chatbots",excerpt:"Exploring the evolution from simple chatbots to sophisticated AI agents that can take actions, make decisions, and operate autonomously.",content:`We're witnessing a fundamental shift in AI applications. The era of simple question-and-answer chatbots is giving way to sophisticated autonomous agents that can perceive, reason, and act in complex environments.

## What Makes an Agent "Autonomous"?

True AI agents possess several key capabilities:
- **Perception**: Understanding their environment and context
- **Planning**: Breaking down complex goals into actionable steps
- **Action**: Executing tasks in the real world
- **Learning**: Improving performance over time
- **Adaptation**: Adjusting to new situations and requirements

## The Agent Architecture

In my work developing AI agents for lead generation, I've found that effective agents typically follow this pattern:

**1. Perception Layer**: Gathering and processing information
**2. Reasoning Engine**: Planning and decision-making
**3. Action Interface**: Executing tasks and interactions
**4. Memory System**: Maintaining context and learning
**5. Feedback Loop**: Continuous improvement

## Real-World Applications

**Lead Generation Agents**: Our autonomous agents at Palmmind can:
- Research potential customers
- Craft personalized outreach messages
- Schedule follow-ups
- Qualify leads based on responses
- Update CRM systems automatically

**Home Automation**: The Raspberry Pi voice agent I built demonstrates how AI can:
- Understand natural language commands
- Control multiple IoT devices
- Learn user preferences
- Anticipate needs based on patterns

## The Technology Stack

**Modern AI agents leverage**:
- **LLMs for reasoning**: GPT-4, Claude for complex decision-making
- **Vector databases**: For long-term memory and context
- **API integrations**: Connecting to external services
- **Workflow engines**: Orchestrating multi-step processes
- **Monitoring systems**: Tracking performance and errors

## Challenges and Solutions

**Challenge: Reliability**
- Solution: Implement robust error handling and fallback mechanisms
- Use confidence scoring for decision-making
- Human oversight for critical actions

**Challenge: Context Management**
- Solution: Sophisticated memory systems
- Hierarchical context (short-term, long-term, episodic)
- Context compression and summarization

**Challenge: Security**
- Solution: Sandboxed execution environments
- Permission-based action systems
- Audit trails for all agent actions

## The Future Landscape

**Near-term (1-2 years)**:
- Agents that can handle complex customer service scenarios
- Personal assistants that manage calendars, emails, and tasks
- Development agents that can write and debug code

**Medium-term (3-5 years)**:
- Agents that can negotiate contracts and make business decisions
- Research agents that can conduct scientific investigations
- Creative agents that can produce original content and art

**Long-term (5+ years)**:
- Agents that can manage entire business processes
- Scientific agents that can formulate and test hypotheses
- Governance agents that can assist in policy-making

## Building Responsible Agents

As we develop more powerful autonomous agents, we must consider:

**Transparency**: Users should understand what agents are doing and why
**Control**: Humans should always be able to intervene and override
**Accountability**: Clear responsibility chains for agent actions
**Privacy**: Protecting user data and maintaining confidentiality
**Fairness**: Ensuring agents don't perpetuate biases or discrimination

## Practical Implementation Tips

**Start Small**: Begin with narrow, well-defined tasks
**Measure Everything**: Track performance, errors, and user satisfaction
**Iterate Rapidly**: Use feedback to improve agent capabilities
**Plan for Scale**: Design systems that can handle increased complexity
**Maintain Human Oversight**: Always have humans in the loop for critical decisions

## Conclusion

Autonomous AI agents represent the next frontier in artificial intelligence. They promise to transform how we work, live, and interact with technology. But with great power comes great responsibility. As we build these systems, we must ensure they serve humanity's best interests while respecting our values and maintaining our agency.

The future belongs to those who can successfully bridge the gap between human intelligence and artificial capability, creating agents that amplify our abilities rather than replace our judgment.`,date:"2024-11-28",readTime:"9 min read",tags:["AI Agents","Automation","Future Tech","Autonomous Systems"],icon:d.A,color:"text-green-400"}];return(0,a.jsx)("div",{className:"pt-24 pb-16 px-4 sm:px-6 lg:px-8",children:(0,a.jsxs)("div",{className:"max-w-6xl mx-auto",children:[(0,a.jsxs)("div",{className:"text-center mb-16",children:[(0,a.jsx)("h1",{className:"text-5xl font-bold mb-6",children:(0,a.jsx)("span",{className:"text-transparent bg-clip-text bg-gradient-to-r from-cyan-400 to-pink-400",children:"NEURAL_BLOG"})}),(0,a.jsx)("div",{className:"w-24 h-1 bg-gradient-to-r from-cyan-400 to-pink-400 mx-auto mb-6"}),(0,a.jsx)("p",{className:"text-gray-400 font-mono text-lg",children:"> thoughts_on_ai_and_future.md"})]}),(0,a.jsxs)("div",{className:"mb-16",children:[(0,a.jsx)("h2",{className:"text-2xl font-bold text-white mb-8 font-mono",children:"> FEATURED_POST"}),(0,a.jsx)(i.Zp,{className:"bg-gradient-to-r from-gray-900/80 to-gray-800/80 border-cyan-400/50 hover:border-cyan-400 transition-all duration-300",children:(0,a.jsx)(i.Wu,{className:"p-8",children:(0,a.jsxs)("div",{className:"grid lg:grid-cols-2 gap-8 items-center",children:[(0,a.jsxs)("div",{children:[(0,a.jsxs)("div",{className:"flex items-center space-x-3 mb-4",children:[(0,a.jsx)(o.A,{className:"w-8 h-8 text-cyan-400"}),(0,a.jsx)(s.E,{variant:"outline",className:"border-cyan-400 text-cyan-400 font-mono",children:"FEATURED"})]}),(0,a.jsx)("h3",{className:"text-3xl font-bold text-white mb-4",children:e[0].title}),(0,a.jsx)("p",{className:"text-gray-300 mb-6 leading-relaxed",children:e[0].excerpt}),(0,a.jsxs)("div",{className:"flex items-center space-x-4 text-sm text-gray-400 mb-6",children:[(0,a.jsxs)("div",{className:"flex items-center space-x-1",children:[(0,a.jsx)(m.A,{className:"w-4 h-4"}),(0,a.jsx)("span",{children:e[0].date})]}),(0,a.jsxs)("div",{className:"flex items-center space-x-1",children:[(0,a.jsx)(h.A,{className:"w-4 h-4"}),(0,a.jsx)("span",{children:e[0].readTime})]})]}),(0,a.jsx)(r.$,{className:"bg-gradient-to-r from-cyan-500 to-pink-500 hover:from-cyan-600 hover:to-pink-600 text-black font-bold",children:(0,a.jsxs)(g(),{href:`/blog/${e[0].id}`,className:"flex items-center",children:["READ_ARTICLE ",(0,a.jsx)(u,{className:"w-4 h-4 ml-2"})]})})]}),(0,a.jsxs)("div",{className:"relative",children:[(0,a.jsx)("div",{className:"w-full h-64 bg-gradient-to-br from-cyan-400/20 to-pink-400/20 rounded-lg flex items-center justify-center",children:(0,a.jsx)(o.A,{className:"w-24 h-24 text-cyan-400 animate-pulse"})}),(0,a.jsx)("div",{className:"absolute -top-4 -right-4 w-8 h-8 bg-cyan-400 rounded-full animate-pulse"}),(0,a.jsx)("div",{className:"absolute -bottom-4 -left-4 w-6 h-6 bg-pink-400 rounded-full animate-pulse delay-300"})]})]})})})]}),(0,a.jsxs)("div",{className:"mb-16",children:[(0,a.jsx)("h2",{className:"text-2xl font-bold text-white mb-8 font-mono",children:"> ALL_ARTICLES"}),(0,a.jsx)("div",{className:"grid gap-8",children:e.map((e,t)=>{let n=e.icon;return(0,a.jsx)(i.Zp,{className:"bg-gray-900/50 border-gray-700 hover:border-cyan-400/50 transition-all duration-300 group",children:(0,a.jsx)(i.Wu,{className:"p-6",children:(0,a.jsxs)("div",{className:"grid lg:grid-cols-4 gap-6",children:[(0,a.jsx)("div",{className:"lg:col-span-3",children:(0,a.jsxs)("div",{className:"flex items-start space-x-4 mb-4",children:[(0,a.jsx)("div",{className:"p-3 bg-gray-800 rounded-lg group-hover:bg-gray-700 transition-colors",children:(0,a.jsx)(n,{className:`w-6 h-6 ${e.color}`})}),(0,a.jsxs)("div",{className:"flex-1",children:[(0,a.jsx)("h3",{className:"text-xl font-bold text-white mb-2 group-hover:text-cyan-400 transition-colors",children:e.title}),(0,a.jsx)("p",{className:"text-gray-300 mb-4 leading-relaxed",children:e.excerpt}),(0,a.jsx)("div",{className:"flex flex-wrap gap-2 mb-4",children:e.tags.map((e,t)=>(0,a.jsx)(s.E,{variant:"outline",className:"border-gray-600 text-gray-400 hover:border-cyan-400 hover:text-cyan-400 transition-colors font-mono text-xs",children:e},t))})]})]})}),(0,a.jsxs)("div",{className:"flex flex-col justify-between",children:[(0,a.jsxs)("div",{className:"space-y-2 text-sm text-gray-400 mb-4",children:[(0,a.jsxs)("div",{className:"flex items-center space-x-2",children:[(0,a.jsx)(m.A,{className:"w-4 h-4"}),(0,a.jsx)("span",{className:"font-mono",children:e.date})]}),(0,a.jsxs)("div",{className:"flex items-center space-x-2",children:[(0,a.jsx)(h.A,{className:"w-4 h-4"}),(0,a.jsx)("span",{className:"font-mono",children:e.readTime})]})]}),(0,a.jsx)(r.$,{variant:"outline",className:"border-pink-400 text-pink-400 hover:bg-pink-400/10 font-mono w-full",children:(0,a.jsxs)(g(),{href:`/blog/${e.id}`,className:"flex items-center justify-center",children:["READ_MORE ",(0,a.jsx)(u,{className:"w-4 h-4 ml-2"})]})})]})]})})},t)})})]}),(0,a.jsx)(i.Zp,{className:"bg-gradient-to-r from-gray-900/80 to-gray-800/80 border-purple-400/50",children:(0,a.jsxs)(i.Wu,{className:"p-8 text-center",children:[(0,a.jsx)("h3",{className:"text-2xl font-bold text-white mb-4 font-mono",children:"> SUBSCRIBE_TO_UPDATES"}),(0,a.jsx)("p",{className:"text-gray-300 mb-6",children:"Get notified when I publish new articles about AI, machine learning, and the future of technology."}),(0,a.jsxs)("div",{className:"flex flex-col sm:flex-row gap-4 max-w-md mx-auto",children:[(0,a.jsx)("input",{type:"email",placeholder:"your@email.com",className:"flex-1 bg-black border border-gray-600 rounded px-4 py-3 text-white font-mono focus:border-purple-400 focus:outline-none transition-colors"}),(0,a.jsx)(r.$,{className:"bg-gradient-to-r from-purple-500 to-pink-500 hover:from-purple-600 hover:to-pink-600 text-white font-bold font-mono",children:"SUBSCRIBE"})]})]})})]})})}},2654:(e,t,n)=>{"use strict";n.d(t,{A:()=>a});let a=(0,n(6373).A)("Brain",[["path",{d:"M12 5a3 3 0 1 0-5.997.125 4 4 0 0 0-2.526 5.77 4 4 0 0 0 .556 6.588A4 4 0 1 0 12 18Z",key:"l5xja"}],["path",{d:"M12 5a3 3 0 1 1 5.997.125 4 4 0 0 1 2.526 5.77 4 4 0 0 1-.556 6.588A4 4 0 1 1 12 18Z",key:"ep3f8r"}],["path",{d:"M15 13a4.5 4.5 0 0 1-3-4 4.5 4.5 0 0 1-3 4",key:"1p4c4q"}],["path",{d:"M17.599 6.5a3 3 0 0 0 .399-1.375",key:"tmeiqw"}],["path",{d:"M6.003 5.125A3 3 0 0 0 6.401 6.5",key:"105sqy"}],["path",{d:"M3.477 10.896a4 4 0 0 1 .585-.396",key:"ql3yin"}],["path",{d:"M19.938 10.5a4 4 0 0 1 .585.396",key:"1qfode"}],["path",{d:"M6 18a4 4 0 0 1-1.967-.516",key:"2e4loj"}],["path",{d:"M19.967 17.484A4 4 0 0 1 18 18",key:"159ez6"}]])},2704:()=>{},2837:(e,t,n)=>{"use strict";n.d(t,{default:()=>f});var a=n(687),i=n(5814),s=n.n(i),r=n(6189),o=n(9384),l=n(2348),c=n(4366),d=n(8869),m=n(7800),h=n(375),u=n(2080),p=n(3931);let g=[{href:"/",label:"Home",icon:c.A},{href:"/about",label:"About",icon:d.A},{href:"/experience",label:"Experience",icon:m.A},{href:"/projects",label:"Projects",icon:h.A},{href:"/blog",label:"Blog",icon:u.A},{href:"/contact",label:"Contact",icon:p.A}];function f(){let e=(0,r.usePathname)();return(0,a.jsx)("nav",{className:"fixed top-0 left-0 right-0 z-50 bg-black/80 backdrop-blur-md border-b border-cyan-500/20",children:(0,a.jsx)("div",{className:"max-w-7xl mx-auto px-4 sm:px-6 lg:px-8",children:(0,a.jsxs)("div",{className:"flex items-center justify-between h-16",children:[(0,a.jsx)(s(),{href:"/",className:"text-xl font-mono font-bold text-cyan-400 hover:text-pink-400 transition-colors",children:"<DIBAS/>"}),(0,a.jsx)("div",{className:"hidden md:flex space-x-8",children:g.map(t=>{let n=t.icon;return(0,a.jsxs)(s(),{href:t.href,className:function(...e){return(0,l.QP)((0,o.$)(e))}("flex items-center space-x-2 px-3 py-2 text-sm font-medium transition-all duration-200",e===t.href?"text-cyan-400 border-b-2 border-cyan-400":"text-gray-300 hover:text-pink-400 hover:border-b-2 hover:border-pink-400"),children:[(0,a.jsx)(n,{className:"w-4 h-4"}),(0,a.jsx)("span",{children:t.label})]},t.href)})}),(0,a.jsx)("div",{className:"md:hidden",children:(0,a.jsx)("button",{className:"text-gray-300 hover:text-cyan-400",children:(0,a.jsx)(c.A,{className:"w-6 h-6"})})})]})})})}},3033:e=>{"use strict";e.exports=require("next/dist/server/app-render/work-unit-async-storage.external.js")},3148:(e,t,n)=>{"use strict";n.d(t,{A:()=>a});let a=(0,n(6373).A)("Clock",[["circle",{cx:"12",cy:"12",r:"10",key:"1mglay"}],["polyline",{points:"12 6 12 12 16 14",key:"68esgv"}]])},3198:(e,t,n)=>{Promise.resolve().then(n.t.bind(n,4536,23))},3295:e=>{"use strict";e.exports=require("next/dist/server/app-render/after-task-async-storage.external.js")},3873:e=>{"use strict";e.exports=require("path")},4536:(e,t,n)=>{let{createProxy:a}=n(9844);e.exports=a("D:\\dibas-portfolio\\node_modules\\next\\dist\\client\\app-dir\\link.js")},4592:(e,t,n)=>{"use strict";n.d(t,{$:()=>c});var a=n(7413),i=n(1120),s=n(403),r=n(662),o=n(6819);let l=(0,r.F)("inline-flex items-center justify-center gap-2 whitespace-nowrap rounded-md text-sm font-medium ring-offset-background transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 [&_svg]:pointer-events-none [&_svg]:size-4 [&_svg]:shrink-0",{variants:{variant:{default:"bg-primary text-primary-foreground hover:bg-primary/90",destructive:"bg-destructive text-destructive-foreground hover:bg-destructive/90",outline:"border border-input bg-background hover:bg-accent hover:text-accent-foreground",secondary:"bg-secondary text-secondary-foreground hover:bg-secondary/80",ghost:"hover:bg-accent hover:text-accent-foreground",link:"text-primary underline-offset-4 hover:underline"},size:{default:"h-10 px-4 py-2",sm:"h-9 rounded-md px-3",lg:"h-11 rounded-md px-8",icon:"h-10 w-10"}},defaultVariants:{variant:"default",size:"default"}}),c=i.forwardRef(({className:e,variant:t,size:n,asChild:i=!1,...r},c)=>{let d=i?s.DX:"button";return(0,a.jsx)(d,{className:(0,o.cn)(l({variant:t,size:n,className:e})),ref:c,...r})});c.displayName="Button"},5301:(e,t,n)=>{Promise.resolve().then(n.bind(n,1979))},5805:(e,t,n)=>{"use strict";n.d(t,{A:()=>a});let a=(0,n(6373).A)("Zap",[["path",{d:"M4 14a1 1 0 0 1-.78-1.63l9.9-10.2a.5.5 0 0 1 .86.46l-1.92 6.02A1 1 0 0 0 13 10h7a1 1 0 0 1 .78 1.63l-9.9 10.2a.5.5 0 0 1-.86-.46l1.92-6.02A1 1 0 0 0 11 14z",key:"1xq2db"}]])},5894:(e,t,n)=>{Promise.resolve().then(n.t.bind(n,5814,23))},6575:(e,t,n)=>{Promise.resolve().then(n.t.bind(n,6444,23)),Promise.resolve().then(n.t.bind(n,6042,23)),Promise.resolve().then(n.t.bind(n,8170,23)),Promise.resolve().then(n.t.bind(n,9477,23)),Promise.resolve().then(n.t.bind(n,9345,23)),Promise.resolve().then(n.t.bind(n,2089,23)),Promise.resolve().then(n.t.bind(n,6577,23)),Promise.resolve().then(n.t.bind(n,1307,23))},6700:(e,t,n)=>{"use strict";n.d(t,{A:()=>a});let a=(0,n(6373).A)("Building",[["rect",{width:"16",height:"20",x:"4",y:"2",rx:"2",ry:"2",key:"76otgf"}],["path",{d:"M9 22v-4h6v4",key:"r93iot"}],["path",{d:"M8 6h.01",key:"1dz90k"}],["path",{d:"M16 6h.01",key:"1x0f13"}],["path",{d:"M12 6h.01",key:"1vi96p"}],["path",{d:"M12 10h.01",key:"1nrarc"}],["path",{d:"M12 14h.01",key:"1etili"}],["path",{d:"M16 10h.01",key:"1m94wz"}],["path",{d:"M16 14h.01",key:"1gbofw"}],["path",{d:"M8 10h.01",key:"19clt8"}],["path",{d:"M8 14h.01",key:"6423bh"}]])},6819:(e,t,n)=>{"use strict";n.d(t,{cn:()=>s});var a=n(5986),i=n(8974);function s(...e){return(0,i.QP)((0,a.$)(e))}},7157:(e,t,n)=>{Promise.resolve().then(n.bind(n,2837))},7204:(e,t,n)=>{Promise.resolve().then(n.t.bind(n,6346,23)),Promise.resolve().then(n.t.bind(n,7924,23)),Promise.resolve().then(n.t.bind(n,5656,23)),Promise.resolve().then(n.t.bind(n,99,23)),Promise.resolve().then(n.t.bind(n,8243,23)),Promise.resolve().then(n.t.bind(n,8827,23)),Promise.resolve().then(n.t.bind(n,2763,23)),Promise.resolve().then(n.t.bind(n,7173,23))},8014:(e,t,n)=>{"use strict";n.r(t),n.d(t,{default:()=>d,metadata:()=>c});var a=n(7413),i=n(1455),s=n.n(i),r=n(195),o=n.n(r);n(2704);var l=n(1979);let c={title:"Dibas Pratap Basnet - AI/ML Engineer",description:"AI/ML Engineer specializing in LLM-driven applications and automation",icons:{icon:[{url:"/favicon.png",type:"image/svg+xml"},{url:"/favicon.ico",sizes:"16x16",type:"image/x-icon"}]},generator:"v0.dev"};function d({children:e}){return(0,a.jsxs)("html",{lang:"en",className:"dark",children:[(0,a.jsxs)("head",{children:[(0,a.jsx)("link",{rel:"icon",href:"/favicon.png",type:"image/svg+xml"}),(0,a.jsx)("link",{rel:"icon",href:"/favicon.ico",sizes:"16x16",type:"image/x-icon"})]}),(0,a.jsx)("body",{className:`${s().variable} ${o().variable} font-sans bg-black text-white antialiased`,children:(0,a.jsxs)("div",{className:"min-h-screen bg-gradient-to-br from-black via-gray-900 to-black",children:[(0,a.jsx)(l.default,{}),(0,a.jsx)("main",{children:e})]})})]})}},9121:e=>{"use strict";e.exports=require("next/dist/server/app-render/action-async-storage.external.js")},9294:e=>{"use strict";e.exports=require("next/dist/server/app-render/work-async-storage.external.js")},9455:(e,t,n)=>{"use strict";n.d(t,{E:()=>o});var a=n(7413);n(1120);var i=n(662),s=n(6819);let r=(0,i.F)("inline-flex items-center rounded-full border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2",{variants:{variant:{default:"border-transparent bg-primary text-primary-foreground hover:bg-primary/80",secondary:"border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80",destructive:"border-transparent bg-destructive text-destructive-foreground hover:bg-destructive/80",outline:"text-foreground"}},defaultVariants:{variant:"default"}});function o({className:e,variant:t,...n}){return(0,a.jsx)("div",{className:(0,s.cn)(r({variant:t}),e),...n})}},9636:(e,t,n)=>{"use strict";n.r(t),n.d(t,{GlobalError:()=>r.a,__next_app__:()=>m,pages:()=>d,routeModule:()=>h,tree:()=>c});var a=n(5239),i=n(8088),s=n(8170),r=n.n(s),o=n(893),l={};for(let e in o)0>["default","tree","pages","GlobalError","__next_app__","routeModule"].indexOf(e)&&(l[e]=()=>o[e]);n.d(t,l);let c={children:["",{children:["blog",{children:["__PAGE__",{},{page:[()=>Promise.resolve().then(n.bind(n,2399)),"D:\\dibas-portfolio\\app\\blog\\page.tsx"]}]},{}]},{layout:[()=>Promise.resolve().then(n.bind(n,8014)),"D:\\dibas-portfolio\\app\\layout.tsx"],"not-found":[()=>Promise.resolve().then(n.t.bind(n,7398,23)),"next/dist/client/components/not-found-error"],forbidden:[()=>Promise.resolve().then(n.t.bind(n,9999,23)),"next/dist/client/components/forbidden-error"],unauthorized:[()=>Promise.resolve().then(n.t.bind(n,5284,23)),"next/dist/client/components/unauthorized-error"]}]}.children,d=["D:\\dibas-portfolio\\app\\blog\\page.tsx"],m={require:n,loadChunk:()=>Promise.resolve()},h=new a.AppPageRouteModule({definition:{kind:i.RouteKind.APP_PAGE,page:"/blog/page",pathname:"/blog",bundlePath:"",filename:"",appPaths:[]},userland:{loaderTree:c}})}};var t=require("../../webpack-runtime.js");t.C(e);var n=e=>t(t.s=e),a=t.X(0,[967,417],()=>n(9636));module.exports=a})();